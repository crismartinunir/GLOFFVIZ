{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b94a05ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas, terminado en /:  C:/TFM_OPF/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  % Valores no estandarizados\n",
      "code                                 0.940671\n",
      "created_datetime                   100.000000\n",
      "product_name                              NaN\n",
      "generic_name                              NaN\n",
      "quantity                                  NaN\n",
      "...                                       ...\n",
      "inositol_100g                        0.000247\n",
      "carnitine_100g                       0.000247\n",
      "sulphate_100g                        0.000402\n",
      "nitrate_100g                         0.000494\n",
      "acidity_100g                         0.000031\n",
      "\n",
      "[162 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Solicitar el directorio del archivo CSV al usuario\n",
    "input_directory = input(\"Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas, terminado en /: \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not input_directory.endswith('/'):\n",
    "    input_directory += '/'\n",
    "\n",
    "# Definir el path del archivo CSV\n",
    "csv_file_name = 'dataset_columnas_eliminadas_pandas.csv'\n",
    "csvsincol_path = os.path.join(input_directory, csv_file_name)\n",
    "\n",
    "\n",
    "# Carga el dataset\n",
    "df2 = pd.read_csv(csvsincol_path, encoding='utf-8', sep='\\t', low_memory=False)\n",
    "\n",
    "# Inicializa un diccionario para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "# Función para detectar valores fuera de rango en columnas numéricas\n",
    "def detect_outliers_numeric(column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = ((column < lower_bound) | (column > upper_bound))\n",
    "    return outliers.mean() * 100\n",
    "\n",
    "# Función para detectar valores no estandarizados en columnas categóricas\n",
    "def detect_non_standard_categorical(column):\n",
    "    freq = column.value_counts(normalize=True)\n",
    "    threshold = 0.01  # Umbral para considerar un valor como raro\n",
    "    rare_values = freq[freq < threshold]\n",
    "    non_standard = column.isin(rare_values.index)\n",
    "    return non_standard.mean() * 100\n",
    "\n",
    "# Analiza cada columna del DataFrame\n",
    "for column in df2.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df2[column]):\n",
    "        # Columnas numéricas\n",
    "        percentage_outliers = detect_outliers_numeric(df2[column])\n",
    "        results[column] = percentage_outliers\n",
    "    elif pd.api.types.is_string_dtype(df2[column]):\n",
    "        # Columnas categóricas\n",
    "        percentage_non_standard = detect_non_standard_categorical(df2[column])\n",
    "        results[column] = percentage_non_standard\n",
    "    else:\n",
    "        results[column] = None  # Otros tipos de datos no analizados\n",
    "\n",
    "# Crea un DataFrame con los resultados\n",
    "results_df2 = pd.DataFrame.from_dict(results, orient='index', columns=['% Valores no estandarizados'])\n",
    "\n",
    "# Muestra los resultados\n",
    "print(results_df2)\n",
    "\n",
    "# Guarda los resultados en un archivo CSV en mismo directorio del Notebook para analizarlos\n",
    "results_df2.to_csv('resultados_analisis.csv', sep='\\t', encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7769d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas, terminado en /:  C:/TFM_OPF/\n",
      "Directorio donde guardar el archivo CSV de salida tras limpieza de nulos, terminado en /:  :  C:/TFM_OPF/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo CSV con campos nulos convertidos a NaN guardado en: C:/TFM_OPF/dataset_columnas_eliminadas_pandas_NaN.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Solicitar el directorio del archivo CSV de entrada al usuario\n",
    "input_directory = input(\"Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas, terminado en /: \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not input_directory.endswith('/'):\n",
    "    input_directory += '/'\n",
    "\n",
    "# Solicitar el directorio del archivo CSV de salida al usuario\n",
    "output_directory = input(\"Directorio donde guardar el archivo CSV de salida tras limpieza de nulos, terminado en /:  : \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not output_directory.endswith('/'):\n",
    "    output_directory += '/'\n",
    "\n",
    "# Definir los nombres de los archivos CSV\n",
    "input_csv_file_name = 'dataset_columnas_eliminadas_pandas.csv'\n",
    "output_csv_file_name = 'dataset_columnas_eliminadas_pandas_NaN.csv'\n",
    "\n",
    "# Construir las rutas completas de los archivos CSV\n",
    "csv_path = os.path.join(input_directory, input_csv_file_name)\n",
    "output_csv_path = os.path.join(output_directory, output_csv_file_name)\n",
    "\n",
    "# Carga el dataset\n",
    "df3 = pd.read_csv(csv_path, encoding='utf-8', sep='\\t', low_memory=False)\n",
    "\n",
    "# Reemplazar cadenas vacías y otros valores nulos o específicos con NaN\n",
    "df3.replace(['', 'NULL', 'NA', 'unknown'], pd.NA, inplace=True)\n",
    "\n",
    "# Guardar el DataFrame resultante en un archivo CSV\n",
    "df3.to_csv(output_csv_path, sep='\\t', encoding='utf-8', index=False)\n",
    "\n",
    "print(f\"Archivo CSV con campos nulos convertidos a NaN guardado en: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c2e232c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas_NaN, terminado en /:  C:/TFM_OPF/\n",
      "Directorio donde guardar el archivo CSV de salida tras limpieza de valores no estandarizados, terminado en /:  C:/TFM_OPF/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset limpio de valores no estandarizados guardado en: C:/TFM_OPF/dataset_columnas_limpias.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Solicitar el directorio del archivo CSV al usuario\n",
    "input_directory = input(\"Directorio donde se encuentra el archivo CSV dataset_columnas_eliminadas_pandas_NaN, terminado en /: \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not input_directory.endswith('/'):\n",
    "    input_directory += '/'\n",
    "\n",
    "# Definir el nombre del archivo CSV\n",
    "csv_file_name = 'dataset_columnas_eliminadas_pandas_NaN.csv'\n",
    "\n",
    "# Construir la ruta completa del archivo CSV\n",
    "csvsincol_path = os.path.join(input_directory, csv_file_name)\n",
    "\n",
    "# Carga el dataset\n",
    "df5 = pd.read_csv(csvsincol_path, encoding='utf-8', sep='\\t', low_memory=False)\n",
    "\n",
    "# Inicializa un diccionario para almacenar los resultados\n",
    "results = {}\n",
    "\n",
    "# Función para detectar valores fuera de rango en columnas numéricas\n",
    "def detect_outliers_numeric(column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = ((column < lower_bound) | (column > upper_bound))\n",
    "    return outliers\n",
    "\n",
    "# Función para detectar valores no estandarizados en columnas categóricas\n",
    "def detect_non_standard_categorical(column):\n",
    "    freq = column.value_counts(normalize=True)\n",
    "    threshold = 0.01  # Umbral para considerar un valor como raro\n",
    "    rare_values = freq[freq < threshold]\n",
    "    non_standard = column.isin(rare_values.index)\n",
    "    return non_standard\n",
    "\n",
    "# Analiza cada columna del DataFrame y almacena los resultados\n",
    "for column in df5.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df5[column]):\n",
    "        # Columnas numéricas\n",
    "        outliers = detect_outliers_numeric(df5[column])\n",
    "        results[column] = outliers\n",
    "    elif pd.api.types.is_string_dtype(df5[column]):\n",
    "        # Columnas categóricas\n",
    "        non_standard = detect_non_standard_categorical(df5[column])\n",
    "        results[column] = non_standard\n",
    "    else:\n",
    "        results[column] = None  # Otros tipos de datos no analizados\n",
    "\n",
    "# Lista de columnas a excluir del proceso de eliminación\n",
    "exclude_columns = ['code', 'created_datetime']\n",
    "\n",
    "# Eliminar valores no estandarizados en las columnas restantes\n",
    "for column, mask in results.items():\n",
    "    if column not in exclude_columns and mask is not None:\n",
    "        df5.loc[mask, column] = pd.NA\n",
    "\n",
    "# Solicitar el directorio del archivo CSV de salida al usuario\n",
    "output_directory = input(\"Directorio donde guardar el archivo CSV de salida tras limpieza de valores no estandarizados, terminado en /: \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not output_directory.endswith('/'):\n",
    "    output_directory += '/'\n",
    "\n",
    "# Definir el nombre del archivo CSV de salida\n",
    "output_csv_file_name = 'dataset_columnas_limpias.csv'\n",
    "\n",
    "# Construir la ruta completa del archivo CSV de salida\n",
    "output_csv_path = os.path.join(output_directory, output_csv_file_name)\n",
    "# Guardar el DataFrame resultante en un archivo CSV\n",
    "df5.to_csv(output_csv_path, sep='\\t', encoding='utf-8', index=False)\n",
    "\n",
    "print(f\"Dataset limpio de valores no estandarizados guardado en: {output_csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa9b66db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Directorio donde se encuentra el archivo CSV archivo CSV limpio, terminado en /:  C:/TFM_OPF/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset limpio tiene 3236626 filas y 162 columnas.\n",
      "                  % Valores no estandarizados\n",
      "code                                 0.940671\n",
      "created_datetime                   100.000000\n",
      "product_name                              NaN\n",
      "generic_name                              NaN\n",
      "quantity                                  NaN\n",
      "...                                       ...\n",
      "inositol_100g                        0.000124\n",
      "carnitine_100g                       0.000000\n",
      "sulphate_100g                        0.000494\n",
      "nitrate_100g                         0.000278\n",
      "acidity_100g                         0.000000\n",
      "\n",
      "[162 rows x 1 columns]\n",
      "Resultados del análisis guardados en: resultados_analisis_limpio.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Solicitar el directorio del archivo CSV limpio al usuario\n",
    "output_directory = input(\"Directorio donde se encuentra el archivo CSV limpio, terminado en /: \")\n",
    "\n",
    "# Asegurarse de que el directorio ingresado termine con una barra diagonal\n",
    "if not output_directory.endswith('/'):\n",
    "    output_directory += '/'\n",
    "\n",
    "# Definir el nombre del archivo CSV limpio\n",
    "output_csv_file_name = 'dataset_columnas_limpias.csv'\n",
    "\n",
    "# Construir la ruta completa del archivo CSV limpio\n",
    "output_csv_path = os.path.join(output_directory, output_csv_file_name)\n",
    "\n",
    "# Carga el dataset limpio\n",
    "df_clean = pd.read_csv(output_csv_path, encoding='utf-8', sep='\\t', low_memory=False)\n",
    "\n",
    "# Obtener el número de filas y columnas\n",
    "num_rows, num_columns = df_clean.shape\n",
    "print(f\"El dataset limpio tiene {num_rows} filas y {num_columns} columnas.\")\n",
    "\n",
    "# Inicializa un diccionario para almacenar los resultados\n",
    "results_clean = {}\n",
    "\n",
    "# Función para detectar valores fuera de rango en columnas numéricas\n",
    "def detect_outliers_numeric(column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "    outliers = ((column < lower_bound) | (column > upper_bound))\n",
    "    return outliers.mean() * 100\n",
    "\n",
    "# Función para detectar valores no estandarizados en columnas categóricas\n",
    "def detect_non_standard_categorical(column):\n",
    "    freq = column.value_counts(normalize=True)\n",
    "    threshold = 0.01  # Umbral para considerar un valor como raro\n",
    "    rare_values = freq[freq < threshold]\n",
    "    non_standard = column.isin(rare_values.index)\n",
    "    return non_standard.mean() * 100\n",
    "\n",
    "# Analiza cada columna del DataFrame limpio\n",
    "for column in df_clean.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df_clean[column]):\n",
    "        # Columnas numéricas\n",
    "        percentage_outliers = detect_outliers_numeric(df_clean[column])\n",
    "        results_clean[column] = percentage_outliers\n",
    "    elif pd.api.types.is_string_dtype(df_clean[column]):\n",
    "        # Columnas categóricas\n",
    "        percentage_non_standard = detect_non_standard_categorical(df_clean[column])\n",
    "        results_clean[column] = percentage_non_standard\n",
    "    else:\n",
    "        results_clean[column] = None  # Otros tipos de datos no analizados\n",
    "\n",
    "# Crea un DataFrame con los resultados\n",
    "results_clean_df = pd.DataFrame.from_dict(results_clean, orient='index', columns=['% Valores no estandarizados'])\n",
    "\n",
    "# Muestra los resultados\n",
    "print(results_clean_df)\n",
    "\n",
    "# Guarda los resultados en un archivo CSV el el mismo directorio del Notebook para analizarlos\n",
    "results_clean_df.to_csv('resultados_analisis_limpio.csv', sep='\\t', encoding='utf-8')\n",
    "\n",
    "print(f\"Resultados del análisis guardados en: resultados_analisis_limpio.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9459282f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
